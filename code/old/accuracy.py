{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ae34af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2020 The HuggingFace Datasets Authors and the current dataset script contributor.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"Accuracy metric.\"\"\"\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import datasets\n",
    "\n",
    "\n",
    "_DESCRIPTION = \"\"\"\n",
    "Accuracy is the proportion of correct predictions among the total number of cases processed. It can be computed with:\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "TP: True positive\n",
    "TN: True negative\n",
    "FP: False positive\n",
    "FN: False negative\n",
    "\"\"\"\n",
    "\n",
    "_KWARGS_DESCRIPTION = \"\"\"\n",
    "Args:\n",
    "    predictions: Predicted labels, as returned by a model.\n",
    "    references: Ground truth labels.\n",
    "    normalize: If False, return the number of correctly classified samples.\n",
    "        Otherwise, return the fraction of correctly classified samples.\n",
    "    sample_weight: Sample weights.\n",
    "Returns:\n",
    "    accuracy: Accuracy score.\n",
    "Examples:\n",
    "\n",
    "    >>> accuracy_metric = datasets.load_metric(\"accuracy\")\n",
    "    >>> results = accuracy_metric.compute(references=[0, 1], predictions=[0, 1])\n",
    "    >>> print(results)\n",
    "    {'accuracy': 1.0}\n",
    "\"\"\"\n",
    "\n",
    "_CITATION = \"\"\"\\\n",
    "@article{scikit-learn,\n",
    "  title={Scikit-learn: Machine Learning in {P}ython},\n",
    "  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n",
    "         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n",
    "         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n",
    "         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n",
    "  journal={Journal of Machine Learning Research},\n",
    "  volume={12},\n",
    "  pages={2825--2830},\n",
    "  year={2011}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@datasets.utils.file_utils.add_start_docstrings(_DESCRIPTION, _KWARGS_DESCRIPTION)\n",
    "class Accuracy(datasets.Metric):\n",
    "    def _info(self):\n",
    "        return datasets.MetricInfo(\n",
    "            description=_DESCRIPTION,\n",
    "            citation=_CITATION,\n",
    "            inputs_description=_KWARGS_DESCRIPTION,\n",
    "            features=datasets.Features(\n",
    "                {\n",
    "                    \"predictions\": datasets.Sequence(datasets.Value(\"int32\")),\n",
    "                    \"references\": datasets.Sequence(datasets.Value(\"int32\")),\n",
    "                }\n",
    "                if self.config_name == \"multilabel\"\n",
    "                else {\n",
    "                    \"predictions\": datasets.Value(\"int32\"),\n",
    "                    \"references\": datasets.Value(\"int32\"),\n",
    "                }\n",
    "            ),\n",
    "            reference_urls=[\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\"],\n",
    "        )\n",
    "\n",
    "    def _compute(self, predictions, references, normalize=True, sample_weight=None):\n",
    "        return {\n",
    "            \"accuracy\": accuracy_score(\n",
    "                references, predictions, normalize=normalize, sample_weight=sample_weight\n",
    "            ).item(),\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
