Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at lvwerra/gpt2-imdb and are newly initialized: ['transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'v_head.summary.weight', 'v_head.summary.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at lvwerra/gpt2-imdb and are newly initialized: ['transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'v_head.summary.weight', 'v_head.summary.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Begin next-word using HF GPT-2 demo
Input sequence:
Machine learning with PyTorch can do amazing
Tokenized input data structure:
{'input_ids': tensor([[37573,  4673,   351,  9485, 15884,   354,   460,   466,  4998]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}
Token IDs and their words:
tensor(37573) Machine
tensor(4673)  learning
tensor(351)  with
tensor(9485)  Py
tensor(15884) Tor
tensor(354) ch
tensor(460)  can
tensor(466)  do
tensor(4998)  amazing
All logits for next word:
tensor([[-114.9652, -118.0908, -123.3014,  ..., -124.5989, -127.7998,
         -118.4347]])
torch.Size([1, 50257])
Predicted token ID of next word:
1243
Predicted next word for sequence:
 things
End demo
Begin next-word using HF GPT-2 demo
Input sequence:
Machine learning with PyTorch can do amazing
Tokenized input data structure:
{'input_ids': tensor([[37573,  4673,   351,  9485, 15884,   354,   460,   466,  4998]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}
Token IDs and their words:
tensor(37573) Machine
tensor(4673)  learning
tensor(351)  with
tensor(9485)  Py
tensor(15884) Tor
tensor(354) ch
tensor(460)  can
tensor(466)  do
tensor(4998)  amazing
All logits for next word:
tensor([[-114.9652, -118.0908, -123.3014,  ..., -124.5989, -127.7998,
         -118.4347]])
torch.Size([1, 50257])
Predicted token ID of next word:
1243
Predicted next word for sequence:
 things
End demo
Begin next-word using HF GPT-2 demo
Input sequence:
connie own
Tokenized input data structure:
{'input_ids': tensor([[ 1102, 11952,   898]]), 'attention_mask': tensor([[1, 1, 1]])}
Token IDs and their words:
tensor(1102) con
tensor(11952) nie
tensor(898)  own
All logits for next word:
tensor([[-86.0371, -81.7704, -89.6549,  ..., -93.6331, -92.7520, -87.4399]])
torch.Size([1, 50257])
Predicted token ID of next word:
262
Predicted next word for sequence:
 the
End demo
Input sequence:
connie own
Tokenized input data structure:
{'input_ids': tensor([[ 1102, 11952,   898]]), 'attention_mask': tensor([[1, 1, 1]])}
Token IDs and their words:
tensor(1102) con
tensor(11952) nie
tensor(898)  own
All logits for next word:
tensor([[-86.0371, -81.7704, -89.6549,  ..., -93.6331, -92.7520, -87.4399]])
torch.Size([1, 50257])
Predicted token ID of next word:
262
Predicted next word for sequence:
 the
End demo
Input sequence:
connie own
Tokenized input data structure:
{'input_ids': tensor([[ 1102, 11952,   898]]), 'attention_mask': tensor([[1, 1, 1]])}
Token IDs and their words:
tensor(1102) con
tensor(11952) nie
tensor(898)  own
All logits for next word:
tensor([[-86.0371, -81.7704, -89.6549,  ..., -93.6331, -92.7520, -87.4399]])
torch.Size([1, 50257])
Predicted token ID of next word:
262
Predicted next word for sequence:
 the
End demo
Input sequence:
connie own
Tokenized input data structure:
{'input_ids': tensor([[ 1102, 11952,   898]]), 'attention_mask': tensor([[1, 1, 1]])}
Token IDs and their words:
tensor(1102) con
tensor(11952) nie
tensor(898)  own
All logits for next word:
tensor([[-86.0371, -81.7704, -89.6549,  ..., -93.6331, -92.7520, -87.4399]])
torch.Size([1, 50257])
Predicted token ID of next word:
262
Predicted next word for sequence:
 the
Input sequence:
connie own
Tokenized input data structure:
{'input_ids': tensor([[ 1102, 11952,   898]]), 'attention_mask': tensor([[1, 1, 1]])}
Token IDs and their words:
tensor(1102) con
tensor(11952) nie
tensor(898)  own
All logits for next word:
tensor([[-86.0371, -81.7704, -89.6549,  ..., -93.6331, -92.7520, -87.4399]])
torch.Size([1, 50257])
Predicted token ID of next word:
262
Predicted next word for sequence:
 the
  0%|                                                   | 0/200 [00:00<?, ?it/s]
  0%|                                                   | 0/200 [00:00<?, ?it/s]
  0%|                                                   | 0/200 [00:00<?, ?it/s]
  0%|                                                   | 0/200 [00:00<?, ?it/s]
/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  0%|                                                   | 0/200 [00:00<?, ?it/s]
/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 2128.14it/s]
/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  This is separate from the ipykernel package so we can avoid doing imports until
  0%|                                                   | 0/200 [00:00<?, ?it/s]
/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 6070.25it/s]
/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  This is separate from the ipykernel package so we can avoid doing imports until

  0%|                                                   | 0/200 [00:13<?, ?it/s]
/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 6037.19it/s]
/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  This is separate from the ipykernel package so we can avoid doing imports until

  0%|                                                   | 0/200 [00:58<?, ?it/s]
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/opt/anaconda3/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 149, in check_network_status
    status_response = self._interface.communicate_network_status()
  File "/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 125, in communicate_network_status
    resp = self._communicate_network_status(status)
  File "/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 397, in _communicate_network_status
    resp = self._communicate(req, local=True)
  File "/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 222, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 227, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
Exception in thread ChkStopThr:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/opt/anaconda3/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 167, in check_status
    status_response = self._interface.communicate_stop_status()
  File "/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 114, in communicate_stop_status
    resp = self._communicate_stop_status(status)
  File "/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 387, in _communicate_stop_status
    resp = self._communicate(req, local=True)
  File "/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 222, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 227, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
Error in callback <function _WandbInit._resume_backend at 0x7f8797271560> (for pre_run_cell):

  0%|                                                   | 0/200 [00:12<?, ?it/s]
Error in callback <function _WandbInit._pause_backend at 0x7f8797271f80> (for post_run_cell):
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/wandb_init.py", line 954, in init
    run = wi.init()
  File "/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/wandb_init.py", line 471, in init
    self._wl._global_run_stack[-1].finish()
  File "/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 1538, in finish
    tel.feature.finish = True
  File "/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/lib/telemetry.py", line 43, in __exit__
    self._run._telemetry_callback(self._obj)
  File "/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 470, in _telemetry_callback
    self._telemetry_flush()
  File "/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 481, in _telemetry_flush
    self._backend.interface._publish_telemetry(self._telemetry_obj)
  File "/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 73, in _publish_telemetry
    self._publish(rec)
  File "/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/interface/interface_queue.py", line 49, in _publish
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
Error in callback <function _WandbInit._resume_backend at 0x7f8797271560> (for pre_run_cell):
Problem at: /var/folders/g6/dmtl65514z1f6797p1f74l1w0000gn/T/ipykernel_30002/1076489368.py 2 <module>
[34m[1mwandb[39m[22m: [32m[41mERROR[39m[49m Abnormal program exit
Error in callback <function _WandbInit._pause_backend at 0x7f8797271f80> (for post_run_cell):